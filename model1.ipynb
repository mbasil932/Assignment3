{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNo4JNlXi6Bk",
        "outputId": "37e8b3a5-b914-4663-f212-5112b286ebdb"
      },
      "source": [
        "import sys\r\n",
        "from matplotlib import pyplot\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "def load_dataset():\r\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\r\n",
        "\ttrainY = to_categorical(trainY)\r\n",
        "\ttestY = to_categorical(testY)\r\n",
        "\treturn trainX, trainY, testX, testY\r\n",
        "\r\n",
        "def prep_pixels(train, test):\r\n",
        "\t# convert from integers to floats\r\n",
        "\ttrain_norm = train.astype('float32')\r\n",
        "\ttest_norm = test.astype('float32')\r\n",
        "\t# normalize to range 0-1\r\n",
        "\ttrain_norm = train_norm / 255.0\r\n",
        "\ttest_norm = test_norm / 255.0\r\n",
        "\t# return normalized images\r\n",
        "\treturn train_norm, test_norm\r\n",
        "\r\n",
        "# define cnn model\r\n",
        "def define_model():\r\n",
        "\tmodel = Sequential()\r\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\r\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\r\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\r\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\r\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\r\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\r\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(Flatten())\r\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\r\n",
        "\tmodel.add(Dropout(0.2))\r\n",
        "\tmodel.add(Dense(10, activation='softmax'))\r\n",
        "\t# compile model\r\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\r\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\treturn model\r\n",
        "\r\n",
        "# plot diagnostic learning curves\r\n",
        "def summarize_diagnostics(history):\r\n",
        "\t# plot loss\r\n",
        "\tpyplot.subplot(211)\r\n",
        "\tpyplot.title('Cross Entropy Loss')\r\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\r\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\r\n",
        "\t# plot accuracy\r\n",
        "\tpyplot.subplot(212)\r\n",
        "\tpyplot.title('Classification Accuracy')\r\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\r\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\r\n",
        "\t# save plot to file\r\n",
        "\tfilename = sys.argv[0].split('/')[-1]\r\n",
        "\tpyplot.savefig(filename + '_plot.png')\r\n",
        "\tpyplot.close()\r\n",
        "\r\n",
        "# run the test harness for evaluating a model\r\n",
        "def run_test_harness():\r\n",
        "\t# load dataset\r\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\r\n",
        "\t# prepare pixel data\r\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\r\n",
        "\t# define model\r\n",
        "\tmodel = define_model()\r\n",
        "\t# fit model\r\n",
        "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\r\n",
        "\t# evaluate model\r\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\r\n",
        "\tprint('> %.3f' % (acc * 100.0))\r\n",
        "\t# learning curves\r\n",
        "\tsummarize_diagnostics(history)\r\n",
        "\r\n",
        "# entry point, run the test harness\r\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}